{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys dependancy to change path for config file\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import googlemaps\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from config import sqlpassword, password, gmaps_password\n",
    "from datetime import datetime, timedelta, date\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the distance for the radius calculation\n",
    "distance = 30\n",
    "#define how far back historical data will be pulled\n",
    "timespan = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the google maps api with an API key\n",
    "gmaps = googlemaps.Client(key=f\"{gmaps_password}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a start time to see how long the script takes to run\n",
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an end date\n",
    "end_date = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a dictionary of key value pairs that accepts a month and returns the first month of the quarter\n",
    "quarter_start = {12:{'Start':10, 'Quarter':'Q4'},\n",
    "                 11:{'Start':10, 'Quarter':'Q4'},\n",
    "                 10:{'Start':10, 'Quarter':'Q4'},\n",
    "                 9:{'Start':7, 'Quarter':'Q3'},\n",
    "                 8:{'Start':7, 'Quarter':'Q3'},\n",
    "                 7:{'Start':7, 'Quarter':'Q3'},\n",
    "                 6:{'Start':4, 'Quarter':'Q2'},\n",
    "                 5:{'Start':4, 'Quarter':'Q2'},\n",
    "                 4:{'Start':4, 'Quarter':'Q2'},\n",
    "                 3:{'Start':1, 'Quarter':'Q1'},\n",
    "                 2:{'Start':1, 'Quarter':'Q1'},\n",
    "                 1:{'Start':1, 'Quarter':'Q1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a start date that's the beginning of the past 4 full quarters.  \n",
    "#Will include 4 full quarters and the current partial quarter.\n",
    "start_date = end_date.replace(year = end_date.year - 1, month = quarter_start[end_date.month]['Start'], day = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the server through engine\n",
    "engine = create_engine(f'{sqlpassword}')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the historical data as a dataframe\n",
    "historical_data = pd.read_sql(f\"SELECT id, origin_city, origin_state, pickup_zip_code, dest_city, \\\n",
    "                         dest_state, consignee_zip_code, pickup_date, carrier_line_haul, miles,\\\n",
    "                             CASE equipment WHEN 'V' THEN 'V' \\\n",
    "                             WHEN 'VF' THEN 'V' \\\n",
    "                             WHEN 'VR' THEN 'V' \\\n",
    "                             WHEN 'F' THEN 'F' \\\n",
    "                             WHEN 'FSD' THEN 'F' \\\n",
    "                             WHEN 'FT' THEN 'F' \\\n",
    "                             WHEN 'SD' THEN 'F' \\\n",
    "                             WHEN 'R' THEN 'R' \\\n",
    "                                 END AS equipment, \\\n",
    "                         CASE accessorial1 WHEN 'FUEL' THEN CAST(carrier_accessorial_rate1 as double precision) END AS one, \\\n",
    "                         CASE accessorial2 WHEN 'FUEL' THEN CAST(carrier_accessorial_rate2 as double precision) END AS two, \\\n",
    "                         CASE accessorial3 WHEN 'FUEL' THEN CAST(carrier_accessorial_rate3 as double precision) END AS three,\\\n",
    "                         CASE accessorial4 WHEN 'FUEL' THEN CAST(carrier_accessorial_rate4 as double precision) END AS four, \\\n",
    "                         CASE accessorial5 WHEN 'FUEL' THEN CAST(carrier_accessorial_rate5 as double precision) END AS five, \\\n",
    "                         CASE accessorial6 WHEN 'FUEL' THEN CAST(carrier_accessorial_rate6 as double precision) END AS six, \\\n",
    "                         CASE accessorial7 WHEN 'FUEL' THEN CAST(carrier_accessorial_rate7 as double precision) END AS seven, \\\n",
    "                         CASE accessorial8 WHEN 'FUEL' THEN CAST(carrier_accessorial_rate8 as double precision) END AS eight\\\n",
    "                         FROM aljex_load \\\n",
    "                         WHERE pickup_date >='{start_date}' \\\n",
    "                         AND pickup_date <='{end_date}' \\\n",
    "                         AND status IN ('RELEASED', 'DELIVERED')\\\n",
    "                         AND equipment IN ('V','VF','VR','F','FSD','FT','SD','R') \\\n",
    "                         AND office NOT IN ('BV','CC','CL','LN','NO','VA','VE')\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in null values with 0\n",
    "historical_data = historical_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert miles string to an integer\n",
    "historical_data['miles'] = historical_data['miles'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out the 0 miles loads\n",
    "historical_data = historical_data[historical_data['miles']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an all-in rate column\n",
    "historical_data['All in Rate'] = historical_data['carrier_line_haul'] + historical_data['one'] + historical_data['two'] + historical_data['three'] + historical_data['four'] + historical_data['five'] + historical_data['six'] + historical_data['seven'] + historical_data['eight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "historical_data = historical_data[['id',\n",
    "                                   'origin_city', \n",
    "                                   'origin_state',\n",
    "                                   'pickup_zip_code',\n",
    "                                   'dest_city',\n",
    "                                   'dest_state',\n",
    "                                   'consignee_zip_code',\n",
    "                                   'pickup_date',\n",
    "                                   'miles',\n",
    "                                   'equipment',\n",
    "                                   'All in Rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rename columns\n",
    "historical_data = historical_data.rename(columns = {'id':'Pro #',\n",
    "                                                   'origin_city':'Orig City',\n",
    "                                                   'origin_state':'Orig State',\n",
    "                                                   'pickup_zip_code':'Pickup Zip',\n",
    "                                                   'dest_city':'Dest City',\n",
    "                                                   'dest_state':'Dest State',\n",
    "                                                   'consignee_zip_code':'Dest Zip',\n",
    "                                                   'miles':'Miles',\n",
    "                                                   'pickup_date':'Ship Date', \n",
    "                                                   'equipment':'Truck Type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create combined city, state for origin and destinations\n",
    "historical_data['Origin'] = historical_data['Orig City'] + \", \" + historical_data['Orig State']\n",
    "historical_data['Dest'] = historical_data['Dest City'] + \", \" + historical_data['Dest State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the excel bid template\n",
    "bid_data = pd.read_excel('radius template.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate origin and destination city/state\n",
    "bid_data['Origin'] = bid_data['Orig City'] + \", \" + bid_data['Orig State']\n",
    "bid_data['Dest'] = bid_data['Dest City'] + \", \" + bid_data['Dest State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a comprehensive list of historical data and bid data cities\n",
    "cities = pd.concat([historical_data['Origin'],historical_data['Dest'], bid_data['Origin'], bid_data['Dest']]).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the column in the newly created dataframe from 0 to City\n",
    "cities = cities.rename(columns = {0:'City'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the coordinates that were previously stored.\n",
    "stored_coordinates = pd.read_csv('stored_records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the cities and stored coordinates dataframes to see what records we have already collected data on\n",
    "cities = cities.merge(stored_coordinates, left_on='City', right_on='Original City', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns from the dataframe\n",
    "cities = cities.drop(columns = ['Original City','Returned City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab all of the cities that don't have saved records\n",
    "cities = cities.loc[cities['Lat'].isnull()]['City'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a unique list of new cities that we don't have saved records for.\n",
    "new_cities = list(cities['City'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterate through the list of new cities grabing the geolocation of each and appending them to the stored_coordinates dataframe\n",
    "for x in range(0,len(new_cities)):\n",
    "    try:\n",
    "        city = new_cities[x]\n",
    "        results = gmaps.geocode(city)\n",
    "        address = results[0]['formatted_address']\n",
    "        lat = results[0]['geometry']['location']['lat']\n",
    "        lng = results[0]['geometry']['location']['lng']\n",
    "        stored_coordinates = stored_coordinates.append({'Original City':city, 'Returned City':address,'Lat':lat, 'Lng':lng}, ignore_index=True)\n",
    "        print(f'{x} of {len(new_cities)}')\n",
    "    except IndexError:\n",
    "        print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save out the stored coordinates dataframe with the new records so we can access it again next time\n",
    "stored_coordinates.to_csv('stored_records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the returned city column from the dataframe\n",
    "stored_coordinates = stored_coordinates.drop(columns = 'Returned City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic Haversine distance formula to calculate distance in miles between origin and destination lat/lon\n",
    "#formula came from https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6\n",
    "#website is also where vectorization is used later to speed up the code\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    MILES = 3959\n",
    "    lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    total_miles = MILES * c\n",
    "    return total_miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grab lat, lng for historical origins\n",
    "historical_data = historical_data.merge(stored_coordinates, left_on='Origin', right_on='Original City')\n",
    "historical_data = historical_data.drop(columns = ['Original City'])\n",
    "historical_data = historical_data.rename(columns = {'Lat':'O Lat', 'Lng':'O Lng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab lat, lng for historical destinations\n",
    "historical_data = historical_data.merge(stored_coordinates, left_on='Dest', right_on='Original City')\n",
    "historical_data = historical_data.drop(columns = ['Original City'])\n",
    "historical_data = historical_data.rename(columns = {'Lat':'D Lat', 'Lng':'D Lng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab lat, lng for bid origins\n",
    "bid_data = bid_data.merge(stored_coordinates, left_on='Origin', right_on='Original City')\n",
    "bid_data = bid_data.drop(columns = ['Original City'])\n",
    "bid_data = bid_data.rename(columns = {'Lat':'O Lat', 'Lng':'O Lng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab lat, lng for bid destinations\n",
    "bid_data = bid_data.merge(stored_coordinates, left_on='Dest', right_on='Original City')\n",
    "bid_data = bid_data.drop(columns = ['Original City'])\n",
    "bid_data = bid_data.rename(columns = {'Lat':'D Lat', 'Lng':'D Lng'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the first quarter start date\n",
    "quarter_start_date = start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a dictionary to help advance quarters iteratively\n",
    "quarter_advance = {1:{'new_month':4, 'years':0},\n",
    "                  4:{'new_month':7, 'years':0},\n",
    "                  7:{'new_month':10, 'years':0},\n",
    "                  10:{'new_month':1, 'years':1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an empty dictionary used in the following iteration.  Will calculate every date span and apend to this dictionary\n",
    "timespan_calculations = {}\n",
    "\n",
    "#6 iterations, one for each of the 4 full quarters, one for the 5th QTD, and one for the full-year timespan\n",
    "for x in range (0, 6):\n",
    "    #if we are on the 6th iteration, perform a 1-year calculation instead of a quarterly calculation\n",
    "    if x == 5:\n",
    "        \n",
    "        #grab the end date defined above\n",
    "        quarter_end_date = end_date\n",
    "        \n",
    "        #calcualte 1 year prior for a one year timespan\n",
    "        quarter_start_date = end_date.replace(year = end_date.year-1) + timedelta(days = 1)\n",
    "        \n",
    "        #set the timespan variable to 1 year\n",
    "        timespan = '1 year'\n",
    "        \n",
    "    #if we are on iteration five, grab the end date defined above instead of the quarter end as we \n",
    "    #are likely in the middle of the quarter and need a QTD calcualation instead\n",
    "    elif x == 4:\n",
    "        \n",
    "        #grab the end date defined above\n",
    "        quarter_end_date = end_date\n",
    "        \n",
    "        #grab the quarter and the year to append to the columns in the dataframe also adding QTD to the variable\n",
    "        timespan = f\"{quarter_start[quarter_start_date.month]['Quarter']} {quarter_start_date.year} QTD\"\n",
    "    \n",
    "    #for all other iterations A.K.A. the first four quarters, calculate quarter start and quarter end\n",
    "    else:\n",
    "        \n",
    "        #define the quarter end date\n",
    "        quarter_end_date = quarter_start_date.replace(month = quarter_advance[quarter_start_date.month]['new_month'], \n",
    "            year = quarter_start_date.year + quarter_advance[quarter_start_date.month]['years']) - timedelta(days = 1)\n",
    "\n",
    "        #grab the quarter and the year to append to the columns in the dataframe\n",
    "        timespan = f\"{quarter_start[quarter_start_date.month]['Quarter']} {quarter_start_date.year}\"\n",
    "\n",
    "    #add the compiled data to the timespan_calculations dictionary\n",
    "    timespan_calculations[timespan] = {'start_date':quarter_start_date, 'end_date':quarter_end_date}\n",
    "    \n",
    "    #override the previously existing quarter start date and advancing it to the start date of the next quarter\n",
    "    quarter_start_date = quarter_end_date + timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab a list of unique timespans\n",
    "timespans = list(timespan_calculations.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can be deleted, used for testing\n",
    "lat1 = bid_data.iloc[0]['O Lat']\n",
    "lng1 = bid_data.iloc[0]['O Lng']\n",
    "lat2 = bid_data.iloc[0]['D Lat']\n",
    "lng2 = bid_data.iloc[0]['D Lng']\n",
    "equipment = bid_data.iloc[0]['Truck Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarterly_averages(lane_df):\n",
    "    df = lane_df[(lane_df['Ship Date'] >= timespan_calculations[timespans[0]]['start_date']) & \n",
    "            (lane_df['Ship Date'] <= timespan_calculations[timespans[0]]['end_date'])]\n",
    "    average0 = df['All in Rate'].mean()\n",
    "    loads0 = len(df)\n",
    "    df = lane_df[(lane_df['Ship Date'] >= timespan_calculations[timespans[1]]['start_date']) & \n",
    "            (lane_df['Ship Date'] <= timespan_calculations[timespans[1]]['end_date'])]\n",
    "    average1 = df['All in Rate'].mean()\n",
    "    loads1 = len(df)\n",
    "    df = lane_df[(lane_df['Ship Date'] >= timespan_calculations[timespans[2]]['start_date']) & \n",
    "            (lane_df['Ship Date'] <= timespan_calculations[timespans[2]]['end_date'])]\n",
    "    average2 = df['All in Rate'].mean()\n",
    "    loads2 = len(df)\n",
    "    df = lane_df[(lane_df['Ship Date'] >= timespan_calculations[timespans[3]]['start_date']) & \n",
    "            (lane_df['Ship Date'] <= timespan_calculations[timespans[3]]['end_date'])]\n",
    "    average3 = df['All in Rate'].mean()\n",
    "    loads3 = len(df)\n",
    "    df = lane_df[(lane_df['Ship Date'] >= timespan_calculations[timespans[4]]['start_date']) & \n",
    "            (lane_df['Ship Date'] <= timespan_calculations[timespans[4]]['end_date'])]\n",
    "    average4 = df['All in Rate'].mean()\n",
    "    loads4 = len(df)\n",
    "    df = lane_df[(lane_df['Ship Date'] >= timespan_calculations[timespans[5]]['start_date']) & \n",
    "            (lane_df['Ship Date'] <= timespan_calculations[timespans[5]]['end_date'])]\n",
    "    average5 = df['All in Rate'].mean()\n",
    "    loads5 = len(df)\n",
    "    return average0, loads0, average1, loads1, average2, loads2, average3, loads3, average4, loads4, average5, loads5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to grab all loads within pre-defined radius, taking equipment into account\n",
    "def radius_pull(lat1, lng1, lat2, lng2, equipment):\n",
    "    \n",
    "    #grab only the data that matched equipment type\n",
    "    origin_radius_df = historical_data.loc[historical_data['Truck Type'] == equipment]\n",
    "    \n",
    "    #vectorize the haversine function, calculating how far historical miles are from bid origin, storing results in a new column\n",
    "    origin_radius_df['O Distance'] = haversine(lat1, lng1, origin_radius_df['O Lat'], origin_radius_df['O Lng'])\n",
    "    \n",
    "    #filter the origin radius dataframe to only have Origin distance less than specified distance above, store in new df\n",
    "    dest_radius_df = origin_radius_df.loc[origin_radius_df['O Distance']<distance]\n",
    "    \n",
    "    #of the remaining results, calculate how far historical miles are from bid destination, storing results in a new column\n",
    "    dest_radius_df['D Distance'] = haversine(lat2, lng2, dest_radius_df['D Lat'], dest_radius_df['D Lng'])\n",
    "    \n",
    "    #filter the dest radius dataframe to only have dest distance less than specified distance above, store in new df\n",
    "    lane_df = dest_radius_df.loc[dest_radius_df['D Distance']<distance]\n",
    "    \n",
    "    average0, loads0, average1, loads1, average2, loads2, average3, loads3, average4, loads4, average5, loads5 = quarterly_averages(lane_df)\n",
    "    \n",
    "    #spit out variables\n",
    "    return lane_df, average0, loads0, average1, loads1, average2, loads2, average3, loads3, average4, loads4, average5, loads5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty columns in the bid_data df\n",
    "bid_data[f'{timespans[0]} Avg. Rate'] = \"\"\n",
    "bid_data[f'{timespans[0]} Loads'] = \"\"\n",
    "bid_data[f'{timespans[1]} Avg. Rate'] = \"\"\n",
    "bid_data[f'{timespans[1]} Loads'] = \"\"\n",
    "bid_data[f'{timespans[2]} Avg. Rate'] = \"\"\n",
    "bid_data[f'{timespans[2]} Loads'] = \"\"\n",
    "bid_data[f'{timespans[3]} Avg. Rate'] = \"\"\n",
    "bid_data[f'{timespans[3]} Loads'] = \"\"\n",
    "bid_data[f'{timespans[4]} Avg. Rate'] = \"\"\n",
    "bid_data[f'{timespans[4]} Loads'] = \"\"\n",
    "bid_data[f'{timespans[5]} Avg. Rate'] = \"\"\n",
    "bid_data[f'{timespans[5]} Loads'] = \"\"\n",
    "bid_data['Lane'] = bid_data['Origin'] + ' to ' + bid_data['Dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create an empty dataframe\n",
    "final_df = pd.DataFrame()\n",
    "#iterate through the rows int he bid_data df performing the radius_pull function for each row\n",
    "for index, row in bid_data.iterrows():\n",
    "    #store the variables spit out of the radius_pull function\n",
    "    lane_df, average0, loads0, average1, loads1, average2, loads2, average3, loads3, average4, loads4, average5, loads5 = radius_pull(row['O Lat'], row['O Lng'], row['D Lat'], row['D Lng'], row['Truck Type'])\n",
    "    #using the .loc function with the index, set the average rate to the variable from the radius_pull function\n",
    "    bid_data.loc[index, f'{timespans[0]} Avg. Rate'] = average0\n",
    "    bid_data.loc[index, f'{timespans[1]} Avg. Rate'] = average1\n",
    "    bid_data.loc[index, f'{timespans[2]} Avg. Rate'] = average2\n",
    "    bid_data.loc[index, f'{timespans[3]} Avg. Rate'] = average3\n",
    "    bid_data.loc[index, f'{timespans[4]} Avg. Rate'] = average4\n",
    "    bid_data.loc[index, f'{timespans[5]} Avg. Rate'] = average5\n",
    "    \n",
    "    #using the .loc function with the index, set the load count to the variable from the radius_pull function\n",
    "    bid_data.loc[index, f'{timespans[0]} Loads'] = loads0\n",
    "    bid_data.loc[index, f'{timespans[1]} Loads'] = loads1\n",
    "    bid_data.loc[index, f'{timespans[2]} Loads'] = loads2\n",
    "    bid_data.loc[index, f'{timespans[3]} Loads'] = loads3\n",
    "    bid_data.loc[index, f'{timespans[4]} Loads'] = loads4\n",
    "    bid_data.loc[index, f'{timespans[5]} Loads'] = loads5\n",
    "    \n",
    "    #in the lane_df, set the bid lane to the current lane in the iterrows function\n",
    "    lane_df['Bid Lane'] = row['Lane']\n",
    "    \n",
    "    #append the lane_df to the final_df\n",
    "    final_df = final_df.append([lane_df])\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the new bid_data df\n",
    "bid_data.to_csv('historicals.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the new final_data df\n",
    "final_df.to_csv('lane_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab an ending \n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate script runtime\n",
    "end-start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
